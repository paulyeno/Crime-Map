##levels(mtc$am)<-c("Automatic","Manual")
#exp data anal
summary(mtcars$mpg)
summary((subset(mtcars,mtcars$am=="Automatic"))$mpg)
summary((subset(mtcars,mtcars$am=="Manual"))$mpg)
aggregate(mpg~am,mean,data=mtcars)
plot(density(mtcars$mpg),
xlab="Miles per Gallon",
main="Density Plot of Miles per Gallon")
#normal dist
boxplot(mpg~am,data=mtcars,
xlab = "Transmission Type",
ylab = "Miles per Gallon",
main = "MPG by Type of Transmission")
#no outliers
t.test(mtcars[mtcars$am=="Automatic","mpg"],mtcars[mtcars$am=="Manual","mpg"])
#pvalue small, reject null hypoth, sig diff btwn mpg man and mpg auto
summary(svlr<-lm(mpg~am,data=mtcars))
#lin reg not good:pval low, but R^2 value is low, means 36% variance in mpg
#explained with  just am so use multi var
cor(mtcarsars)[,"mpg"]
#include covariants<-.75 (and am because required), so include cyl disp hp wt
cor(mtcars[,c("cyl","disp","hp","wt","am")])
#but cyl and disp correlated >90% so not them
summary(mvlr<-lm(mpg~hp+wt+am,data=mtcars))
#high R^2, very low p (7 orders of mag smaller)
anova(svlr,mvlr)
#small p so not stat similar so mvlr better
par(mfrow=c(2,2))
plot(mvlr)
#normally distributed residuals, homoscedastic (same variance)
#tiny p so not by chance, R^2 explains 84% variance
#so can say manual on avg 2.08 more mpg
#http://rstudio-pubs-static.s3.amazonaws.com/
#20516_29b941670a4b42688292b4bb892a660f.html
##mtc<-mtcars
##mtc$am<-factor(mtc$am)
#change am to auto or man
##levels(mtc$am)<-c("Automatic","Manual")
#exp data anal
summary(mtcars$mpg)
summary((subset(mtcars,mtcars$am=="Automatic"))$mpg)
summary((subset(mtcars,mtcars$am=="Manual"))$mpg)
aggregate(mpg~am,mean,data=mtcars)
plot(density(mtcars$mpg),
xlab="Miles per Gallon",
main="Density Plot of Miles per Gallon")
#normal dist
boxplot(mpg~am,data=mtcars,
xlab = "Transmission Type",
ylab = "Miles per Gallon",
main = "MPG by Type of Transmission")
#no outliers
t.test(mtcars[mtcars$am=="Automatic","mpg"],mtcars[mtcars$am=="Manual","mpg"])
#pvalue small, reject null hypoth, sig diff btwn mpg man and mpg auto
summary(svlr<-lm(mpg~am,data=mtcars))
#lin reg not good:pval low, but R^2 value is low, means 36% variance in mpg
#explained with  just am so use multi var
cor(mtcars)[,"mpg"]
#include covariants<-.75 (and am because required), so include cyl disp hp wt
cor(mtcars[,c("cyl","disp","hp","wt","am")])
#but cyl and disp correlated >90% so not them
summary(mvlr<-lm(mpg~hp+wt+am,data=mtcars))
#high R^2, very low p (7 orders of mag smaller)
anova(svlr,mvlr)
#small p so not stat similar so mvlr better
par(mfrow=c(2,2))
plot(mvlr)
#normally distributed residuals, homoscedastic (same variance)
#tiny p so not by chance, R^2 explains 84% variance
#so can say manual on avg 2.08 more mpg
#http://rstudio-pubs-static.s3.amazonaws.com/
#20516_29b941670a4b42688292b4bb892a660f.html
View(mtc)
head(mtc)
head(mtcars)
##mtc<-mtcars
##mtc$am<-factor(mtc$am)
#change am to auto or man
##levels(mtc$am)<-c("Automatic","Manual")
#exp data anal
summary(mtcars$mpg)
summary((subset(mtcars,mtcars$am==0))$mpg)
summary((subset(mtcars,mtcars$am==1))$mpg)
aggregate(mpg~am,mean,data=mtcars)
plot(density(mtcars$mpg),
xlab="Miles per Gallon",
main="Density Plot of Miles per Gallon")
#normal dist
boxplot(mpg~am,data=mtcars,
xlab = "Transmission Type",
ylab = "Miles per Gallon",
main = "MPG by Type of Transmission")
#no outliers
t.test(mtcars[mtcars$am==0,"mpg"],mtcars[mtcars$am==1,"mpg"])
#pvalue small, reject null hypoth, sig diff btwn mpg man and mpg auto
summary(svlr<-lm(mpg~am,data=mtcars))
#lin reg not good:pval low, but R^2 value is low, means 36% variance in mpg
#explained with  just am so use multi var
cor(mtcars)[,"mpg"]
#include covariants<-.75 (and am because required), so include cyl disp hp wt
cor(mtcars[,c("cyl","disp","hp","wt","am")])
#but cyl and disp correlated >90% so not them
summary(mvlr<-lm(mpg~hp+wt+am,data=mtcars))
#high R^2, very low p (7 orders of mag smaller)
anova(svlr,mvlr)
#small p so not stat similar so mvlr better
par(mfrow=c(2,2))
plot(mvlr)
#normally distributed residuals, homoscedastic (same variance)
#tiny p so not by chance, R^2 explains 84% variance
#so can say manual on avg 2.08 more mpg
#http://rstudio-pubs-static.s3.amazonaws.com/
#20516_29b941670a4b42688292b4bb892a660f.html
##mtc<-mtcars
##mtc$am<-factor(mtc$am)
#change am to auto or man
##levels(mtc$am)<-c("Automatic","Manual")
#exp data anal
summary(mtcars$mpg)
summary((subset(mtcars,mtcars$am==0))$mpg)
summary((subset(mtcars,mtcars$am==1))$mpg)
aggregate(mpg~am,mean,data=mtcars)
plot(density(mtcars$mpg),
xlab="Miles per Gallon",
main="Density Plot of Miles per Gallon")
#normal dist
boxplot(mpg~am,data=mtcars,
xlab = "Transmission Type",
ylab = "Miles per Gallon",
main = "MPG by Type of Transmission")
#no outliers
t.test(mtcars[mtcars$am==0,"mpg"],mtcars[mtcars$am==1,"mpg"])
#pvalue small, reject null hypoth, sig diff btwn mpg man and mpg auto
summary(svlr<-lm(mpg~am,data=mtcars))
#lin reg not good:pval low, but R^2 value is low, means 36% variance in mpg
#explained with  just am so use multi var
cor(mtcars)[,"mpg"]
#include covariants<-.75 (and am because required), so include cyl disp hp wt
cor(mtcars[,c("cyl","disp","hp","wt","am")])
#but cyl and disp correlated >90% so not them
summary(mvlr<-lm(mpg~hp+wt+am,data=mtcars))
#high R^2, very low p (7 orders of mag smaller)
anova(svlr,mvlr)
#small p so not stat similar so mvlr better
par(mfrow=c(2,2))
plot(mvlr)
#normally distributed residuals, homoscedastic (same variance)
#tiny p so not by chance, R^2 explains 84% variance
#so can say manual on avg 2.08 more mpg
#http://rstudio-pubs-static.s3.amazonaws.com/
#20516_29b941670a4b42688292b4bb892a660f.html
summary(lm(mpg~cyl+wt,data=mtcars))
-1.5078*4
summary(lm(mpg~cyl,data=mtcars))
nob<-summary(lm(mpg~cyl+wt,data=mtcars))
dick<-summary(lm(mpg~cyl,data=mtcars))
anova(nob,dick)
nob<-(lm(mpg~cyl+wt,data=mtcars))
dick<-(lm(mpg~cyl,data=mtcars))
anova(nob,dick)
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
(4/7)*.15
+20
(4/7)*.15+20+40
(4/7)*1.5+20+40
((4/7)*15)+20+40
((4/7)*15)+30+40
100-(((4/7)*15)+30+40)
90-(((4/7)*15)+30+40)
(90-(((4/7)*15)+30+40))/15
install.packages("rattle")
library(rattle)
rattle()
rattle()
library("rattle");rattle()
library("rattle");rattle()
rattle()
rattle()
install.packages("shiny")
library(shiny)
manipulate
library(manipulate)
install.packages("devtools")
install.packages("rCharts")
library(rMaps)
L2 <- Leaflet$new()
L2$setView(c(29.7632836,  -95.3632715), 10)
L2$tileLayer(provider = "MapQuestOpen.OSM")
L2
data(crime, package = 'ggmap')
library(plyr)
crime_dat = ddply(crime, .(lat, lon), summarise, count = length(address))
crime_dat = toJSONArray2(na.omit(crime_dat), json = F, names = F)
cat(rjson::toJSON(crime_dat[1:2]))
# Add leaflet-heat plugin. Thanks to Vladimir Agafonkin
L2$addAssets(jshead = c(
"http://leaflet.github.io/Leaflet.heat/dist/leaflet-heat.js"
))
# Add javascript to modify underlying chart
L2$setTemplate(afterScript = sprintf("
<script>
var addressPoints = %s
var heat = L.heatLayer(addressPoints).addTo(map)
</script>
", rjson::toJSON(crime_dat)
))
L2
library(rMaps)
L2 <- Leaflet$new()
L2$setView(c(29.7632836,  -95.3632715), 10)
L2$tileLayer(provider = "MapQuestOpen.OSM")
L2
data(crime, package = 'ggmap')
library(plyr)
crime_dat = ddply(crime, .(lat, lon), summarise, count = length(address))
crime_dat = toJSONArray2(na.omit(crime_dat), json = F, names = F)
cat(rjson::toJSON(crime_dat[1:2]))
library(rMaps)
L2 <- Leaflet$new()
L2$setView(c(29.7632836,  -95.3632715), 10)
L2$tileLayer(provider = "MapQuestOpen.OSM")
L2
data(crime, package = 'ggmap')
library(plyr);library(rCharts)
crime_dat = ddply(crime, .(lat, lon), summarise, count = length(address))
crime_dat = toJSONArray2(na.omit(crime_dat), json = F, names = F)
cat(rjson::toJSON(crime_dat[1:2]))
# Add leaflet-heat plugin. Thanks to Vladimir Agafonkin
L2$addAssets(jshead = c(
"http://leaflet.github.io/Leaflet.heat/dist/leaflet-heat.js"
))
# Add javascript to modify underlying chart
L2$setTemplate(afterScript = sprintf("
<script>
var addressPoints = %s
var heat = L.heatLayer(addressPoints).addTo(map)
</script>
", rjson::toJSON(crime_dat)
))
L2
d<-NULL
d<-rbind(c("15 W dover st.","waterbury","connecticut"),
c("1182 spindle hill rd","wolcott","ct"),
c("56 franklin street","waterbury","CT"),
c("60 colt ave","torrington","ct"))
head(crime_dat,1)
tail(crime_dat,1)
head(crime_dat,2)
head(crime_dat,3)
GC1<-function(street,town,state){
street<-gsub(" ","+",street)
town<-gsub(" ","+",town)
state<-gsub(" ","+",state)
urladdy<-url(paste(
"http://www.datasciencetoolkit.org/maps/api/geocode/json?sensor=false&address="
,street,",+",town,",+",state,sep=""))
latlon<-as.numeric(c(substring(readLines(urladdy,n=12)[12],20),
substr(substring(readLines(urladdy,n=11)[11],20),
1,nchar(substring(readLines(urladdy,n=11)[11],20))-1)))
close(urladdy)
return(latlon)
}
GCMat<-function(Mat){
#3 columns of input matrix should be street, town, state
r<-NULL
for(i in 1:nrow(Mat)){
r<-rbind(r,GC1(Mat[i,1],Mat[i,2],Mat[i,3]))
}
return(r)
}
d<-NULL
d<-rbind(c("15 W dover st.","waterbury","connecticut"),
c("1182 spindle hill rd","wolcott","ct"),
c("56 franklin street","waterbury","CT"),
c("60 colt ave","torrington","ct"))
nob<-as.data.frame(GCMat(d))
nob<-cbind(nob,c(1,1,1,1))
nob
nob<-as.data.frame(GCMat(d))
nob
nob<-(GCMat(d))
nob
d
GC1(d[1,])
GC1(d[1,1],d[1,2],d[1,3])
street<-d[1,1]
town<-d[1,1]
town<-d[1,2]
state<-d[1,3]
street<-gsub(" ","+",street)
town<-gsub(" ","+",town)
state<-gsub(" ","+",state)
urladdy<-url(paste(
"http://www.datasciencetoolkit.org/maps/api/geocode/json?sensor=false&address="
,street,",+",town,",+",state,sep=""))
latlon<-as.numeric(c(substring(readLines(urladdy,n=12)[12],20),
substr(substring(readLines(urladdy,n=11)[11],20),
1,nchar(substring(readLines(urladdy,n=11)[11],20))-1)))
lat<-as.numeric((substring(readLines(urladdy,n=12)[12],20))
)
((substring(readLines(urladdy,n=12)[12],20))
)
urladdy
dick<-substring.location((readLines(urladdy)),"lng")
?grep
grep("lng",(readLines(urladdy)),fixed=TRUE)
reanLines(urladdy)
read'Lines(urladdy)
readLines(urladdy)
GC1<-function(street,town,state){
street<-gsub(" ","+",street)
town<-gsub(" ","+",town)
state<-gsub(" ","+",state)
urladdy<-url(paste(
"http://www.datasciencetoolkit.org/maps/api/geocode/json?sensor=false&address="
,street,",+",town,",+",state,sep=""))
latlon<-as.numeric(c(substring(readLines(urladdy,n=53)[53],20),
substr(substring(readLines(urladdy,n=52)[52],20),
1,nchar(substring(readLines(urladdy,n=52)[52],20))-1)))
close(urladdy)
return(latlon)
}
GCMat<-function(Mat){
#3 columns of input matrix should be street, town, state
r<-NULL
for(i in 1:nrow(Mat)){
r<-rbind(r,GC1(Mat[i,1],Mat[i,2],Mat[i,3]))
}
return(r)
}
d<-NULL
d<-rbind(c("15 W dover st.","waterbury","connecticut"),
c("1182 spindle hill rd","wolcott","ct"),
c("56 franklin street","waterbury","CT"),
c("60 colt ave","torrington","ct"))
nob<-(GCMat(d))
nob<-cbind(nob,c(1,1,1,1))
View(nob)
View(nob)
View(nob)
View(nob)
GC1<-function(street,town,state){
street<-gsub(" ","+",street)
town<-gsub(" ","+",town)
state<-gsub(" ","+",state)
urladdy<-url(paste(
"http://www.datasciencetoolkit.org/maps/api/geocode/json?sensor=false&address="
,street,",+",town,",+",state,sep=""))
latlon<-as.numeric(c(substring(readLines(urladdy,n=53)[53],18),
substr(substring(readLines(urladdy,n=52)[52],18),
1,nchar(substring(readLines(urladdy,n=52)[52],18))-1)))
close(urladdy)
return(latlon)
}
GCMat<-function(Mat){
#3 columns of input matrix should be street, town, state
r<-NULL
for(i in 1:nrow(Mat)){
r<-rbind(r,GC1(Mat[i,1],Mat[i,2],Mat[i,3]))
}
return(r)
}
d<-NULL
d<-rbind(c("15 W dover st.","waterbury","connecticut"),
c("1182 spindle hill rd","wolcott","ct"),
c("56 franklin street","waterbury","CT"),
c("60 colt ave","torrington","ct"))
nob<-(GCMat(d))
nob<-cbind(nob,c(1,1,1,1))
nob<-as.list(GCMat(d))
nob<-cbind(nob,c(1,1,1,1))
library(rMaps)
L2 <- Leaflet$new()
L2$setView(c(29.7632836,  -95.3632715), 10)
L2$tileLayer(provider = "MapQuestOpen.OSM")
L2
data(crime, package = 'ggmap')
library(plyr);library(rCharts)
crime_dat = ddply(crime, .(lat, lon), summarise, count = length(address))
crime_dat = toJSONArray2(na.omit(crime_dat), json = F, names = F)
cat(rjson::toJSON(crime_dat[1:2]))
# Add leaflet-heat plugin. Thanks to Vladimir Agafonkin
L2$addAssets(jshead = c(
"http://leaflet.github.io/Leaflet.heat/dist/leaflet-heat.js"
))
# Add javascript to modify underlying chart
L2$setTemplate(afterScript = sprintf("
<script>
var addressPoints = %s
var heat = L.heatLayer(addressPoints).addTo(map)
</script>
", rjson::toJSON(nob)
))
L2
View(nob)
nob<-as.data.frame(GCMat(d))
nob<-cbind(nob,c(1,1,1,1))
View(nob)
View(nob)
library(rMaps)
L2 <- Leaflet$new()
L2$setView(c(41.6,  -73), 10)
L2$tileLayer(provider = "MapQuestOpen.OSM")
L2
data(crime, package = 'ggmap')
library(plyr);library(rCharts)
crime_dat = ddply(crime, .(lat, lon), summarise, count = length(address))
crime_dat = toJSONArray2(na.omit(crime_dat), json = F, names = F)
cat(rjson::toJSON(crime_dat[1:2]))
# Add leaflet-heat plugin. Thanks to Vladimir Agafonkin
L2$addAssets(jshead = c(
"http://leaflet.github.io/Leaflet.heat/dist/leaflet-heat.js"
))
# Add javascript to modify underlying chart
L2$setTemplate(afterScript = sprintf("
<script>
var addressPoints = %s
var heat = L.heatLayer(addressPoints).addTo(map)
</script>
", rjson::toJSON(nob)
))
L2
str(crime_dat)
GC1<-function(street,town,state){
street<-gsub(" ","+",street)
town<-gsub(" ","+",town)
state<-gsub(" ","+",state)
#   urladdy<-url(paste(
#     "http://www.datasciencetoolkit.org/maps/api/geocode/",
#     "json?sensor=false&address=",street,",+",town,",+",state,sep=""))
urladdy<-url(paste(
"http://localhost:1234/maps/api/geocode/",
"json?sensor=false&address=",street,",+",town,",+",state,sep=""))
if(sum(grepl("ZERO_RESULTS",readLines(urladdy,n=4)))>=1){return(NA)}
latnum<-grep("lat",readLines(urladdy,n=67))[1]
lonnum<-grep("lng",readLines(urladdy,n=67))[1]
latchr<-substring(readLines(urladdy,n=latnum)[latnum],18)
lonchr<-substring(readLines(urladdy,n=lonnum)[lonnum],18)
lat<-as.numeric(substr(latchr,1,nchar(latchr)))
lon<-as.numeric(substr(lonchr,1,nchar(lonchr)-1))
latlon<-c(lat,lon)
close(urladdy)
return(latlon)
}
GCMat<-function(Mat){
#3 columns of input matrix should be street, town, state
r<-NULL
for(i in 1:nrow(Mat)){
if(round(i/50)==(i/50)){print(i)}
r<-rbind(r,GC1(Mat[i,1],Mat[i,2],Mat[i,3]))}
return(r)
}
#addy<-read.csv("Heatmap 166.csv",header=F)[,1:3]
### use one of following to import data
# dt<-as.data.frame(GCMat(addy))
### or use the following for WVAA 13 AUG 2013 to 12 AUG 2014
#dt<-read.csv(file="Heatmap 166 13 AUG 2013 to 12 AUG 2014.csv")[,2:3]
setwd("C:/Users/paul.yeno/Dropbox/School/Coursera/9 Developing Data Products")
setwd("~/GitHub/Crime-Map")
setwd("~/GitHub/Crime-Map")
require(slidify)
install.pacages("slidify")
install.packages("slidify")
require(devtools)
install_github("slidify", "ramnathv")
install_github("slidifyLibraries", "ramnathv")
library(slidify)
author('interactive')
slidify("index.Rmd")
slidify("index.Rmd")
slidify("index.Rmd")
library(shiny)
library(shiny);library(plyr);library(rCharts)
#data from data.police.uk for City of London Police for June 2014
data<-read.csv("2014-06-city-of-london-street.csv")[,c(5:6,10:11)]
addy<-NULL
for(i in 1:nrow(data)){addy[i]<-paste(data[i,1],data[i,2])}
data<-cbind(data,addy)
rm(addy)
head(data)
data[,3]
hist(x = data[,3])
library(plyr)
dt<-ddply(.data = data[3])
dt<-summary(data[3])
dt<-summary(data[,3])
dt
hist(dt)
data<-summary(read.csv("2014-06-city-of-london-street.csv")[,10])
print(names(data[1]),data[1])
print(names(data[1])
)
print(c(names(data[1]),data[1]))
print(c(data[1]))
data[1]
da<-names(data)
names(data)<-NULL
data<-summary(read.csv("2014-06-city-of-london-street.csv")[,10])
data<-sort(data)
data
data<-sort(data,decreasing=F)
data<-sort(summary(read.csv("2014-06-city-of-london-street.csv")[,10]),decr=F)
data
data<-sort(summary(read.csv("2014-06-city-of-london-street.csv")[,10]),decr=T)
data
paste(data[1]," incidences of ",dn[1],"!",sep = " ")
library(slidify)
author('interactive')
slidify("index.Rmd")
setwd("~/GitHub/Crime-Map/interactive/interactive")
options(rpubs.upload.method = "internal")
